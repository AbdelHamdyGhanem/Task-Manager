{"ast":null,"code":"import { Aggregator } from \"../../aggregator\";\nimport { ComputeOptions, computeValue } from \"../../core\";\nimport { MingoError } from \"../../types\";\nimport { assert, hashCode, isArray, isString, resolve } from \"../../util\";\nimport { $mergeObjects } from \"../expression\";\n/**\n * Writes the resulting documents of the aggregation pipeline to a collection.\n *\n * The stage can incorporate (insert new documents, merge documents, replace documents,\n * keep existing documents, fail the operation, process documents with a custom update pipeline)\n * the results into an output collection. To use the $merge stage, it must be the last stage in the pipeline.\n *\n * Note: Object are deep cloned for outputing regardless of the ProcessingMode.\n *\n * @param collection\n * @param expr\n * @param options\n * @returns {*}\n */\nexport const $merge = (collection, expr, options) => {\n  const output = isString(expr.into) ? options === null || options === void 0 ? void 0 : options.collectionResolver(expr.into) : expr.into;\n  assert(output instanceof Array, `$merge: option 'into' must resolve to an array`);\n  const onField = expr.on || options.idKey;\n  const getHash = o => {\n    const val = isString(onField) ? resolve(o, onField) : onField.map(s => resolve(o, s));\n    return hashCode(val, options.hashFunction);\n  };\n  const hash = {};\n  // we assuming the lookup expressions are unique\n  for (let i = 0; i < output.length; i++) {\n    const obj = output[i];\n    const k = getHash(obj);\n    assert(!hash[k], \"$merge: 'into' collection must have unique entries for the 'on' field.\");\n    hash[k] = [obj, i];\n  }\n  const copts = ComputeOptions.init(options);\n  return collection.map(o => {\n    const k = getHash(o);\n    if (hash[k]) {\n      const [target, i] = hash[k];\n      // compute variables\n      const variables = computeValue(target, expr.let || {\n        new: \"$$ROOT\"\n      }, null,\n      // 'root' is the item from the iteration.\n      copts.update(o));\n      if (isArray(expr.whenMatched)) {\n        const aggregator = new Aggregator(expr.whenMatched, Object.assign(Object.assign({}, options), {\n          variables\n        }));\n        output[i] = aggregator.run([target])[0];\n      } else {\n        switch (expr.whenMatched) {\n          case \"replace\":\n            output[i] = o;\n            break;\n          case \"fail\":\n            throw new MingoError(\"$merge: failed due to matching as specified by 'whenMatched' option.\");\n          case \"keepExisting\":\n            break;\n          case \"merge\":\n          default:\n            output[i] = $mergeObjects(target, [target, o],\n            // 'root' is the item from the iteration.\n            copts.update(o, {\n              variables\n            }));\n            break;\n        }\n      }\n    } else {\n      switch (expr.whenNotMatched) {\n        case \"discard\":\n          break;\n        case \"fail\":\n          throw new MingoError(\"$merge: failed due to matching as specified by 'whenMatched' option.\");\n        case \"insert\":\n        default:\n          output.push(o);\n          break;\n      }\n    }\n    return o; // passthrough\n  });\n};","map":{"version":3,"names":["Aggregator","ComputeOptions","computeValue","MingoError","assert","hashCode","isArray","isString","resolve","$mergeObjects","$merge","collection","expr","options","output","into","collectionResolver","Array","onField","on","idKey","getHash","o","val","map","s","hashFunction","hash","i","length","obj","k","copts","init","target","variables","let","new","update","whenMatched","aggregator","Object","assign","run","whenNotMatched","push"],"sources":["/Users/abdelghanem/Desktop/tasker/node_modules/mingo/dist/esm/operators/pipeline/merge.js"],"sourcesContent":["import { Aggregator } from \"../../aggregator\";\nimport { ComputeOptions, computeValue } from \"../../core\";\nimport { MingoError } from \"../../types\";\nimport { assert, hashCode, isArray, isString, resolve } from \"../../util\";\nimport { $mergeObjects } from \"../expression\";\n/**\n * Writes the resulting documents of the aggregation pipeline to a collection.\n *\n * The stage can incorporate (insert new documents, merge documents, replace documents,\n * keep existing documents, fail the operation, process documents with a custom update pipeline)\n * the results into an output collection. To use the $merge stage, it must be the last stage in the pipeline.\n *\n * Note: Object are deep cloned for outputing regardless of the ProcessingMode.\n *\n * @param collection\n * @param expr\n * @param options\n * @returns {*}\n */\nexport const $merge = (collection, expr, options) => {\n    const output = isString(expr.into)\n        ? options === null || options === void 0 ? void 0 : options.collectionResolver(expr.into)\n        : expr.into;\n    assert(output instanceof Array, `$merge: option 'into' must resolve to an array`);\n    const onField = expr.on || options.idKey;\n    const getHash = (o) => {\n        const val = isString(onField)\n            ? resolve(o, onField)\n            : onField.map(s => resolve(o, s));\n        return hashCode(val, options.hashFunction);\n    };\n    const hash = {};\n    // we assuming the lookup expressions are unique\n    for (let i = 0; i < output.length; i++) {\n        const obj = output[i];\n        const k = getHash(obj);\n        assert(!hash[k], \"$merge: 'into' collection must have unique entries for the 'on' field.\");\n        hash[k] = [obj, i];\n    }\n    const copts = ComputeOptions.init(options);\n    return collection.map((o) => {\n        const k = getHash(o);\n        if (hash[k]) {\n            const [target, i] = hash[k];\n            // compute variables\n            const variables = computeValue(target, expr.let || { new: \"$$ROOT\" }, null, \n            // 'root' is the item from the iteration.\n            copts.update(o));\n            if (isArray(expr.whenMatched)) {\n                const aggregator = new Aggregator(expr.whenMatched, Object.assign(Object.assign({}, options), { variables }));\n                output[i] = aggregator.run([target])[0];\n            }\n            else {\n                switch (expr.whenMatched) {\n                    case \"replace\":\n                        output[i] = o;\n                        break;\n                    case \"fail\":\n                        throw new MingoError(\"$merge: failed due to matching as specified by 'whenMatched' option.\");\n                    case \"keepExisting\":\n                        break;\n                    case \"merge\":\n                    default:\n                        output[i] = $mergeObjects(target, [target, o], \n                        // 'root' is the item from the iteration.\n                        copts.update(o, { variables }));\n                        break;\n                }\n            }\n        }\n        else {\n            switch (expr.whenNotMatched) {\n                case \"discard\":\n                    break;\n                case \"fail\":\n                    throw new MingoError(\"$merge: failed due to matching as specified by 'whenMatched' option.\");\n                case \"insert\":\n                default:\n                    output.push(o);\n                    break;\n            }\n        }\n        return o; // passthrough\n    });\n};\n"],"mappings":"AAAA,SAASA,UAAU,QAAQ,kBAAkB;AAC7C,SAASC,cAAc,EAAEC,YAAY,QAAQ,YAAY;AACzD,SAASC,UAAU,QAAQ,aAAa;AACxC,SAASC,MAAM,EAAEC,QAAQ,EAAEC,OAAO,EAAEC,QAAQ,EAAEC,OAAO,QAAQ,YAAY;AACzE,SAASC,aAAa,QAAQ,eAAe;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,MAAM,GAAGA,CAACC,UAAU,EAAEC,IAAI,EAAEC,OAAO,KAAK;EACjD,MAAMC,MAAM,GAAGP,QAAQ,CAACK,IAAI,CAACG,IAAI,CAAC,GAC5BF,OAAO,KAAK,IAAI,IAAIA,OAAO,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,OAAO,CAACG,kBAAkB,CAACJ,IAAI,CAACG,IAAI,CAAC,GACvFH,IAAI,CAACG,IAAI;EACfX,MAAM,CAACU,MAAM,YAAYG,KAAK,EAAE,gDAAgD,CAAC;EACjF,MAAMC,OAAO,GAAGN,IAAI,CAACO,EAAE,IAAIN,OAAO,CAACO,KAAK;EACxC,MAAMC,OAAO,GAAIC,CAAC,IAAK;IACnB,MAAMC,GAAG,GAAGhB,QAAQ,CAACW,OAAO,CAAC,GACvBV,OAAO,CAACc,CAAC,EAAEJ,OAAO,CAAC,GACnBA,OAAO,CAACM,GAAG,CAACC,CAAC,IAAIjB,OAAO,CAACc,CAAC,EAAEG,CAAC,CAAC,CAAC;IACrC,OAAOpB,QAAQ,CAACkB,GAAG,EAAEV,OAAO,CAACa,YAAY,CAAC;EAC9C,CAAC;EACD,MAAMC,IAAI,GAAG,CAAC,CAAC;EACf;EACA,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGd,MAAM,CAACe,MAAM,EAAED,CAAC,EAAE,EAAE;IACpC,MAAME,GAAG,GAAGhB,MAAM,CAACc,CAAC,CAAC;IACrB,MAAMG,CAAC,GAAGV,OAAO,CAACS,GAAG,CAAC;IACtB1B,MAAM,CAAC,CAACuB,IAAI,CAACI,CAAC,CAAC,EAAE,wEAAwE,CAAC;IAC1FJ,IAAI,CAACI,CAAC,CAAC,GAAG,CAACD,GAAG,EAAEF,CAAC,CAAC;EACtB;EACA,MAAMI,KAAK,GAAG/B,cAAc,CAACgC,IAAI,CAACpB,OAAO,CAAC;EAC1C,OAAOF,UAAU,CAACa,GAAG,CAAEF,CAAC,IAAK;IACzB,MAAMS,CAAC,GAAGV,OAAO,CAACC,CAAC,CAAC;IACpB,IAAIK,IAAI,CAACI,CAAC,CAAC,EAAE;MACT,MAAM,CAACG,MAAM,EAAEN,CAAC,CAAC,GAAGD,IAAI,CAACI,CAAC,CAAC;MAC3B;MACA,MAAMI,SAAS,GAAGjC,YAAY,CAACgC,MAAM,EAAEtB,IAAI,CAACwB,GAAG,IAAI;QAAEC,GAAG,EAAE;MAAS,CAAC,EAAE,IAAI;MAC1E;MACAL,KAAK,CAACM,MAAM,CAAChB,CAAC,CAAC,CAAC;MAChB,IAAIhB,OAAO,CAACM,IAAI,CAAC2B,WAAW,CAAC,EAAE;QAC3B,MAAMC,UAAU,GAAG,IAAIxC,UAAU,CAACY,IAAI,CAAC2B,WAAW,EAAEE,MAAM,CAACC,MAAM,CAACD,MAAM,CAACC,MAAM,CAAC,CAAC,CAAC,EAAE7B,OAAO,CAAC,EAAE;UAAEsB;QAAU,CAAC,CAAC,CAAC;QAC7GrB,MAAM,CAACc,CAAC,CAAC,GAAGY,UAAU,CAACG,GAAG,CAAC,CAACT,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;MAC3C,CAAC,MACI;QACD,QAAQtB,IAAI,CAAC2B,WAAW;UACpB,KAAK,SAAS;YACVzB,MAAM,CAACc,CAAC,CAAC,GAAGN,CAAC;YACb;UACJ,KAAK,MAAM;YACP,MAAM,IAAInB,UAAU,CAAC,sEAAsE,CAAC;UAChG,KAAK,cAAc;YACf;UACJ,KAAK,OAAO;UACZ;YACIW,MAAM,CAACc,CAAC,CAAC,GAAGnB,aAAa,CAACyB,MAAM,EAAE,CAACA,MAAM,EAAEZ,CAAC,CAAC;YAC7C;YACAU,KAAK,CAACM,MAAM,CAAChB,CAAC,EAAE;cAAEa;YAAU,CAAC,CAAC,CAAC;YAC/B;QACR;MACJ;IACJ,CAAC,MACI;MACD,QAAQvB,IAAI,CAACgC,cAAc;QACvB,KAAK,SAAS;UACV;QACJ,KAAK,MAAM;UACP,MAAM,IAAIzC,UAAU,CAAC,sEAAsE,CAAC;QAChG,KAAK,QAAQ;QACb;UACIW,MAAM,CAAC+B,IAAI,CAACvB,CAAC,CAAC;UACd;MACR;IACJ;IACA,OAAOA,CAAC,CAAC,CAAC;EACd,CAAC,CAAC;AACN,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}